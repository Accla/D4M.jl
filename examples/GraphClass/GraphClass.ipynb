{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use D4M, D4M needs to be on your path. In most environments on the LLSC systems D4M will already be on your path.\n",
    "\n",
    "Frequently in development: it's good to update before use. In the txe1 command line terminal: \n",
    "\n",
    "`module load julia-1.0\n",
    "export JULIA_DEPOT_PATH=/home/gridsan/USERNAME/.julia\n",
    "julia\n",
    "] up D4M`\n",
    "\n",
    "and then restart the notebook, and run these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling D4M [ca196bdc-a701-11e8-3d50-3b5cc8577617]\n",
      "└ @ Base loading.jl:1186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database capabilities loaded!\n",
      "D4M loaded!\n"
     ]
    }
   ],
   "source": [
    "using D4M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 0.5.3\n"
     ]
    }
   ],
   "source": [
    "D4Mver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the version matches the latest version of D4M.jl, found here: https://github.com/n8kim1/D4M.jl/blob/master/src/version.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# D4M Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "D4M is a package for working with Associative Arrays. An Associative Array is a bit like a sparse matrix, but the rows, columns, and values can be either numbers or strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×7 Array{Union{AbstractString, Number},2}:\n",
       " \"\"     \"a\"      \"aa\"     \"aaa\"      \"b\"    \"bb\"     \"bbb\"    \n",
       " \"a\"    \"a-a\"    \"a-aa\"   \"a-aaa\"    \"a-b\"  \"a-bb\"   \"a-bbb\"  \n",
       " \"aa\"   \"aa-a\"   \"aa-aa\"  \"\"         \"\"     \"\"       \"\"       \n",
       " \"aaa\"  \"aaa-a\"  \"\"       \"aaa-aaa\"  \"\"     \"\"       \"\"       \n",
       " \"b\"    \"b-a\"    \"\"       \"\"         \"b-b\"  \"\"       \"\"       \n",
       " \"bb\"   \"bb-a\"   \"\"       \"\"         \"\"     \"bb-bb\"  \"\"       \n",
       " \"bbb\"  \"bbb-a\"  \"\"       \"\"         \"\"     \"\"       \"bbb-bbb\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7×7 Array{Union{AbstractString, Number},2}:\n",
       " \"\"      \"a\"   \"aa\"   \"aaa\"   \"b\"   \"bb\"   \"bbb\"\n",
       " \"a\"    1     1      1       1     1      1     \n",
       " \"aa\"   1     1      0       0     0      0     \n",
       " \"aaa\"  1     0      1       0     0      0     \n",
       " \"b\"    1     0      0       1     0      0     \n",
       " \"bb\"   1     0      0       0     1      0     \n",
       " \"bbb\"  1     0      0       0     0      1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = \"a,a,a,a,a,a,a,aa,aaa,b,bb,bbb,a,aa,aaa,b,bb,bbb,\"\n",
    "column = \"a,aa,aaa,b,bb,bbb,a,a,a,a,a,a,a,aa,aaa,b,bb,bbb,\"\n",
    "values = \"a-a,a-aa,a-aaa,a-b,a-bb,a-bbb,a-a,aa-a,aaa-a,b-a,bb-a,bbb-a,a-a,aa-aa,aaa-aaa,b-b,bb-bb,bbb-bbb,\"\n",
    "\n",
    "A = Assoc(row,column,values)\n",
    "\n",
    "printFull(A)\n",
    "\n",
    "printFull(logical(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This flexibility makes D4M Associative Arrays ideal for representing graph data. Often this involves having string row and column labels, representing the names of vertices and/or edges, and numeric values representing the existance of an edge or the weight of that edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_TODO fix put_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×7 Array{Union{AbstractString, Number},2}:\n",
       " \"\"    \"v1\"  \"v2\"  \"v3\"  \"v4\"  \"v5\"  \"v6\"\n",
       " \"v1\"  \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\" \n",
       " \"v2\"  \"1\"   \"1\"   \"\"    \"\"    \"\"    \"\"  \n",
       " \"v3\"  \"1\"   \"\"    \"1\"   \"\"    \"\"    \"\"  \n",
       " \"v4\"  \"1\"   \"\"    \"\"    \"1\"   \"\"    \"\"  \n",
       " \"v5\"  \"1\"   \"\"    \"\"    \"\"    \"1\"   \"\"  \n",
       " \"v6\"  \"1\"   \"\"    \"\"    \"\"    \"\"    \"1\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7×7 Array{Union{AbstractString, Number},2}:\n",
       " \"\"     \"v1\"   \"v2\"   \"v3\"   \"v4\"   \"v5\"   \"v6\"\n",
       " \"v1\"  1      1      1      1      1      1    \n",
       " \"v2\"  1      1      0      0      0      0    \n",
       " \"v3\"  1      0      1      0      0      0    \n",
       " \"v4\"  1      0      0      1      0      0    \n",
       " \"v5\"  1      0      0      0      1      0    \n",
       " \"v6\"  1      0      0      0      0      1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = \"v1,v1,v1,v1,v1,v1,v1,v2,v3,v4,v5,v6,v1,v2,v3,v4,v5,v6,\"\n",
    "column = \"v1,v2,v3,v4,v5,v6,v1,v1,v1,v1,v1,v1,v1,v2,v3,v4,v5,v6,\"\n",
    "values = \"1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\"\n",
    "\n",
    "A = Assoc(row,column,values)\n",
    "\n",
    "printFull(A)\n",
    "\n",
    "printFull(logical(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/graphEx.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With Associative Arrays, you can extract a subgraph by indexing into the Associative Array. For example, let's just get all the columns with odd vertices and rows with vertices 1-3.\n",
    "\n",
    "Note the last character in an index string is the delimiter, this allows us to do indexing on multiply values with a single string, as cell arrays of strings can get very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×4 Array{Union{AbstractString, Number},2}:\n",
       " \"\"    \"v1\"  \"v3\"  \"v5\"\n",
       " \"v1\"  \"1\"   \"1\"   \"1\" \n",
       " \"v2\"  \"1\"   \"\"    \"\"  \n",
       " \"v3\"  \"1\"   \"1\"   \"\"  \n",
       " \"v4\"  \"1\"   \"\"    \"\"  \n",
       " \"v5\"  \"1\"   \"\"    \"1\" \n",
       " \"v6\"  \"1\"   \"\"    \"\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4×7 Array{Union{AbstractString, Number},2}:\n",
       " \"\"    \"v1\"  \"v2\"  \"v3\"  \"v4\"  \"v5\"  \"v6\"\n",
       " \"v1\"  \"1\"   \"1\"   \"1\"   \"1\"   \"1\"   \"1\" \n",
       " \"v2\"  \"1\"   \"1\"   \"\"    \"\"    \"\"    \"\"  \n",
       " \"v3\"  \"1\"   \"\"    \"1\"   \"\"    \"\"    \"\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printFull(A[:,\"v1,v3,v5,\"])\n",
    "\n",
    "printFull(A[\"v1,:,v3,\",:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also add, subtract, and mutliply Associative Arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×7 Array{Union{AbstractString, Number},2}:\n",
       " \"\"     \"v1\"   \"v2\"   \"v3\"   \"v4\"   \"v5\"   \"v6\"\n",
       " \"v1\"  2.0    1.0    2.0    1.0    2.0    1.0  \n",
       " \"v2\"  2.0    1.0    0.0    0.0    0.0    0.0  \n",
       " \"v3\"  2.0    0.0    2.0    0.0    0.0    0.0  \n",
       " \"v4\"  2.0    0.0    0.0    1.0    0.0    0.0  \n",
       " \"v5\"  2.0    0.0    0.0    0.0    2.0    0.0  \n",
       " \"v6\"  2.0    0.0    0.0    0.0    0.0    1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4×5 Array{Union{AbstractString, Number},2}:\n",
       " \"\"     \"v1\"   \"v4\"   \"v5\"   \"v6\"\n",
       " \"v4\"  1.0    1.0    0.0    0.0  \n",
       " \"v5\"  1.0    0.0    1.0    0.0  \n",
       " \"v6\"  1.0    0.0    0.0    1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7×3 Array{Union{AbstractString, Number},2}:\n",
       " \"\"     \"v2\"   \"v4\"\n",
       " \"v1\"  2      2    \n",
       " \"v2\"  2      1    \n",
       " \"v3\"  1      1    \n",
       " \"v4\"  1      2    \n",
       " \"v5\"  1      1    \n",
       " \"v6\"  1      1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printFull(A + A[:,\"v1,v3,v5,\"]) # A, with odd columns doubled\n",
    "\n",
    "printFull(A - A[\"v1,:,v3,\",:]) # A, with first three columns gone\n",
    "\n",
    "printFull(A * A[:,\"v2,v4,\"]) # A times just a couple of its columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This just a small taste of D4M to get you started. You'll see more as we go through this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating Incidence and Adjacency Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Usually when we parse data into D4M Associative Arrays we put them in an Incidence Matrix format. For review, the rows of an incidence matrix correspond to edges, while the rows correspond to vertices. Incidence matrices can represent a variety of types of graphs, and so can be very useful. You can also easily form any adjacency matrix you need from an incidence matrix.\n",
    "\n",
    "To see how an incidence matrix is formed, let's say for example you have some raw data in a tsv file. The rows IDs of the incidence matrix are some unique identifier of the rows in the original file, in this example they are just the row number in the file. There are generally different columns associated with each row in the tsv file, we combine the column name with each column value to create our column IDs, or vertex IDs in our Incidence matrix. Notice how we have parsed out each individual word in column 3 as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/TSVtoAssoc.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at an example. We are loading an Associative Array with Twitter data (in 10 parts), and looking at the user columns in the first three tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = ReadCSV(\"graphclassdata/A1.csv\");\n",
    "A += ReadCSV(\"graphclassdata/A2.csv\");#error\n",
    "A += ReadCSV(\"graphclassdata/A3.csv\");#error\n",
    "A += ReadCSV(\"graphclassdata/A4.csv\"); #error ?\n",
    "A += ReadCSV(\"graphclassdata/A5.csv\");\n",
    "A += ReadCSV(\"graphclassdata/A6.csv\");\n",
    "A += ReadCSV(\"graphclassdata/A7.csv\");\n",
    "A += ReadCSV(\"graphclassdata/A8.csv\");\n",
    "A += ReadCSV(\"graphclassdata/A9.csv\");\n",
    "A += ReadCSV(\"graphclassdata/A10.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(A.row) # if loaded all 10 files, should be 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129895"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(A.col) # if loaded all 10 files, should be 129895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Union{AbstractString, Number},2}:\n",
       "              \"\"   \"user|Blocker57\"   \"user|Wangjeje\"   \"user|gyanpratika\"\n",
       "  821278781733    0.0                0.0               1.0                \n",
       " 4857479781733    1.0                0.0               0.0                \n",
       " 8653317781733    0.0                1.0               0.0                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printFull(A[1:3,StartsWith(\"user|,\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since the full matrix display is not practical for viewing much more than this, we often look at the triples of the Associative Array. Here are the first two rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2, latlon|++004315..82003012019000000000]  =  1.0\n",
      "  [1, latlon|-+010067..10923207153171000000]  =  1.0\n",
      "  [2, lat|+041.8031090000                  ]  =  1.0\n",
      "  [1, lat|-006.1930137000                  ]  =  1.0\n",
      "  [2, lon|+035.2002100000                  ]  =  1.0\n",
      "  [1, lon|+107.0227511000                  ]  =  1.0\n",
      "  [2, place|682c5a667856ef42               ]  =  1.0\n",
      "  [1, place|85858f3447b85e2b               ]  =  1.0\n",
      "  [1, time|2013-05-22 12:47:08             ]  =  1.0\n",
      "  [2, time|2013-05-22 12:47:32             ]  =  1.0\n",
      "  [1, userID|204683306                     ]  =  1.0\n",
      "  [2, userID|258075949                     ]  =  1.0\n",
      "  [2, user_lower|blocker57                 ]  =  1.0\n",
      "  [1, user_lower|gyanpratika               ]  =  1.0\n",
      "  [2, user|Blocker57                       ]  =  1.0\n",
      "  [1, user|gyanpratika                     ]  =  1.0\n",
      "  [1, word_lower|:(                        ]  =  1.0\n",
      "  [2, word_lower|pastanesi                 ]  =  1.0\n",
      "  [2, word_lower|tarhan                    ]  =  1.0\n",
      "  [1, word|:(                              ]  =  1.0\n",
      "  [2, word|I'm                             ]  =  1.0\n",
      "  [2, word|Pastanesi                       ]  =  1.0\n",
      "  [2, word|Tarhan                          ]  =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(A[1:2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From here we can form a variety of adjacency matrices. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First, we make a bunch of query/filter objects that we can pass into indexing.\n",
    "\n",
    "# All words that start with a letter:\n",
    "realwords = \"word|A,:,word|z\" * Char(127) * \",\";\n",
    "\n",
    "# All hashtags:\n",
    "hashtags = StartsWith(\"word|#\");\n",
    "\n",
    "# Tweets @ someone:\n",
    "directedtweet = StartsWith(\"word|@\");\n",
    "\n",
    "# Usernames:\n",
    "users = StartsWith(\"user|\");\n",
    "\n",
    "# Locations:\n",
    "locs = StartsWith(\"latlon|\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bipartite User-Location Graph\n",
      "  [user|0000The  , latlon|++002459..46269574254468000000]  =  1.0\n",
      "  [user|000chiaki, latlon|++013369..30212434630140720000]  =  1.0\n",
      "\n",
      "Small Symmetric Word-Word Graph\n",
      "  [word|T?rkiye) , word|I'm      ]  =  8.0\n",
      "  [word|w/       , word|I'm      ]  =  14.0\n",
      "  [word|see      , word|It       ]  =  5.0\n",
      "  [word|aku      , word|RT       ]  =  6.0\n",
      "  [word|lah      , word|RT       ]  =  5.0\n",
      "  [word|yg       , word|RT       ]  =  5.0\n",
      "  [word|I'm      , word|T?rkiye) ]  =  8.0\n",
      "  [word|w/       , word|T?rkiye) ]  =  7.0\n",
      "  [word|eu       , word|To       ]  =  5.0\n",
      "  [word|eu       , word|aii      ]  =  10.0\n",
      "  [word|RT       , word|aku      ]  =  6.0\n",
      "  [word|ga       , word|aku      ]  =  8.0\n",
      "  [word|jadi     , word|aku      ]  =  6.0\n",
      "  [word|kamu     , word|aku      ]  =  11.0\n",
      "  [word|eu       , word|baga?eira]  =  5.0\n",
      "  [word|var      , word|bir      ]  =  6.0\n",
      "  [word|eu       , word|cabare   ]  =  5.0\n",
      "  [word|eu       , word|caminh?o ]  =  5.0\n",
      "  [word|lah      , word|dak      ]  =  5.0\n",
      "  [word|yg       , word|dan      ]  =  8.0\n",
      "  [word|eu       , word|e        ]  =  6.0\n",
      "  [word|na       , word|e        ]  =  5.0\n",
      "  [word|en       , word|el       ]  =  8.0\n",
      "  [word|es       , word|el       ]  =  5.0\n",
      "  [word|el       , word|en       ]  =  8.0\n",
      "  [word|el       , word|es       ]  =  5.0\n",
      "  [word|To       , word|eu       ]  =  5.0\n",
      "  [word|aii      , word|eu       ]  =  10.0\n",
      "  [word|baga?eira, word|eu       ]  =  5.0\n",
      "  [word|cabare   , word|eu       ]  =  5.0\n",
      "  [word|caminh?o , word|eu       ]  =  5.0\n",
      "  [word|e        , word|eu       ]  =  6.0\n",
      "  [word|fa?o     , word|eu       ]  =  5.0\n",
      "  [word|fogo     , word|eu       ]  =  5.0\n",
      "  [word|gatinhas , word|eu       ]  =  5.0\n",
      "  [word|levo     , word|eu       ]  =  5.0\n",
      "  [word|ligando  , word|eu       ]  =  5.0\n",
      "  [word|meu      , word|eu       ]  =  5.0\n",
      "  [word|na       , word|eu       ]  =  5.0\n",
      "  [word|nem      , word|eu       ]  =  10.0\n",
      "  [word|o        , word|eu       ]  =  7.0\n",
      "  [word|pega     , word|eu       ]  =  10.0\n",
      "  [word|pro      , word|eu       ]  =  5.0\n",
      "  [word|quiser   , word|eu       ]  =  5.0\n",
      "  [word|eu       , word|fa?o     ]  =  5.0\n",
      "  [word|eu       , word|fogo     ]  =  5.0\n",
      "  [word|aku      , word|ga       ]  =  8.0\n",
      "  [word|kamu     , word|ga       ]  =  9.0\n",
      "  [word|eu       , word|gatinhas ]  =  5.0\n",
      "  [word|var      , word|ili?kisi ]  =  6.0\n",
      "  [word|aku      , word|jadi     ]  =  6.0\n",
      "  [word|aku      , word|kamu     ]  =  11.0\n",
      "  [word|ga       , word|kamu     ]  =  9.0\n",
      "  [word|RT       , word|lah      ]  =  5.0\n",
      "  [word|dak      , word|lah      ]  =  5.0\n",
      "  [word|eu       , word|levo     ]  =  5.0\n",
      "  [word|eu       , word|ligando  ]  =  5.0\n",
      "  [word|se       , word|lo       ]  =  10.0\n",
      "  [word|eu       , word|meu      ]  =  5.0\n",
      "  [word|e        , word|na       ]  =  5.0\n",
      "  [word|eu       , word|na       ]  =  5.0\n",
      "  [word|eu       , word|nem      ]  =  10.0\n",
      "  [word|eu       , word|o        ]  =  7.0\n",
      "  [word|yg       , word|org      ]  =  7.0\n",
      "  [word|w/       , word|others)  ]  =  11.0\n",
      "  [word|eu       , word|pega     ]  =  10.0\n",
      "  [word|yg       , word|pemimpin ]  =  6.0\n",
      "  [word|eu       , word|pro      ]  =  5.0\n",
      "  [word|eu       , word|quiser   ]  =  5.0\n",
      "  [word|yg       , word|sama     ]  =  6.0\n",
      "  [word|lo       , word|se       ]  =  10.0\n",
      "  [word|It       , word|see      ]  =  5.0\n",
      "  [word|bir      , word|var      ]  =  6.0\n",
      "  [word|ili?kisi , word|var      ]  =  6.0\n",
      "  [word|I'm      , word|w/       ]  =  14.0\n",
      "  [word|T?rkiye) , word|w/       ]  =  7.0\n",
      "  [word|others)  , word|w/       ]  =  11.0\n",
      "  [word|RT       , word|yg       ]  =  5.0\n",
      "  [word|dan      , word|yg       ]  =  8.0\n",
      "  [word|org      , word|yg       ]  =  7.0\n",
      "  [word|pemimpin , word|yg       ]  =  6.0\n",
      "  [word|sama     , word|yg       ]  =  6.0\n",
      "\n",
      "Directed User-User Graph\n",
      "  [user|0522Yuhei     , word|@0516Fmb      ]  =  1.0\n",
      "  [user|0714Mizuho    , word|@1224_karen   ]  =  1.0\n",
      "  [user|05Jasmine     , word|@ATluecxk     ]  =  1.0\n",
      "  [user|04_possibility, word|@akochalu     ]  =  1.0\n",
      "  [user|0623Ysik      , word|@akxxx0910    ]  =  1.0\n",
      "  [user|04Nancy       , word|@johncolivert ]  =  1.0\n",
      "  [user|05htm21       , word|@nanohananappa]  =  1.0\n",
      "  [user|0708mio       , word|@sgokhrn      ]  =  1.0\n",
      "  [user|0509ka        , word|@taaanyupi    ]  =  1.0\n",
      "  [user|0648M         , word|@tttyonta     ]  =  1.0\n"
     ]
    }
   ],
   "source": [
    "# Users-Location Graph\n",
    "println(\"Bipartite User-Location Graph\") # number of tweets for each user/location pair\n",
    "Auserloc = transpose(A[:,users]) * A[:,locs]\n",
    "print(Auserloc[1:2,:]) # print the first two rows to get a feel\n",
    "\n",
    "println()\n",
    "\n",
    "# Word-Word Graph\n",
    "println(\"Small Symmetric Word-Word Graph\") # yay for quadratic runtime\n",
    "Asmall = A[1:1000, :]\n",
    "Arealwordsfilter = Asmall[:, realwords] # looking at just the words \n",
    "Awords = transpose(Arealwordsfilter) * Arealwordsfilter # nuber of tweets for each word/word pair\n",
    "Awords = removediag(Awords) \n",
    "print(Awords>4) # display sufficiently high\n",
    "\n",
    "println()\n",
    "\n",
    "# Directed tweets\n",
    "println(\"Directed User-User Graph\")\n",
    "Adir = transpose(A[:,users]) * A[:,directedtweet] # number of each tweets for each \"sender/recipient\" pair\n",
    "print(Adir[11:20, :]) # just a few users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Graph Algorithms in D4M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "D4M has some graph algorithm capabilities built in. Let's take a look at a few examples before we start looking at in-database algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Breadth First Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From our word-word graph, we can see which words that are used together. But what if we want to go out one or two levels more? We can use breadth first search (BFS). We'll start by specifying a few source vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices reached in 3 hops from  I'm, RT,:\n",
      "A Ada Ah Aku And Apa Bom Buenos But Cafe Calum Center Es Eu Facebook Fast Furious Good HP Haha Hahaha Happy Home House I I'm If It It's Iya Jangan Just Kalo La Lo Lol Love Mau Me My No O Oh Pero Pues Que RT Regi?n Restaurant Si So T?rkiye) Tapi Te The To U Udah What Wkwk Y Ya You abis about actually ada adalah ade again ah ahora ai aja ajak akan ako aku al always ama amo anak anda apa aq atau ba bagus baik banyak baru beli belum berapa besok biar biasa bien bikin bile bir birthday bisa blm bola boleh bom bu buat buka call cara che comer como con cuando d d?a da dah dalam dan dapat dari day deh del dengan depan di dia diri disneyland done dong dos dulu e eh el ele em emang en era es eso esok est? este eu excited fast feel first follback follow foto fuck full ga gak ganti gitu give gk good gracias great gua gw ha hacer haha hahahaha hanya happy hari harus hate hati heart ho hoje home hora hours hoy i ih ik ikut il ini itu iya j? jadi jaja jajaja jam jd je jg juga ka kabar kak kalau kamu kapan kasih kau kaya ke kenapa kita kk klo km know ko lagi lah lain lama lang las last lg lho liat little lo lol look looking los love lu luck lupa m?s main mais makan makasih make mal malah malam malem man mana mandi mas masih masuk mata mau mcm mean mejor met meu mi mimum min miss mmg mo msh mucho n n?o na nada nak naman nanti ne need nem new next ng nga ngemil ngerjain ni nice night nih nk nos nya o oke one orang org os others) ou p p? pa pacar para pengen pernah pero please poco por pra pulang pulsa pun punya q quiero read right rumah s? sa salah sama sana say saya sayang se sebelum see sekali sekarang sekolah sem sendiri seorang ser sering si siempre sih sini sm sms sobre som sono sorry start studios su suka susu t ta tadi tahun tak tapi tau td te tem tengo terakhir terus think ti tidak tidur time today todo todos tomorrow tp tu tudo tuh tweet twitter u udah udh um uma una universal uno untuk vai van var ver voc? voy w/ wait wkwk work xD xx y ya yaa yang yg yo you. "
     ]
    }
   ],
   "source": [
    "words = \"word|I'm,word|RT,\"\n",
    "Asearch = logical(Awords)\n",
    "\n",
    "## Run Breadth First Search on Adjancency Schema\n",
    "numsteps=3\n",
    "minDegree=10\n",
    "maxDegree=10000\n",
    "v0 = words # initial vertices\n",
    "Adeg = sum(logical(A),1) # Degree of each node; represents number of tweets each word appeared in\n",
    "# degree filtering lets us get words with sufficiently high frequency\n",
    "\n",
    "v = adjbfs(Asearch,Adeg,v0,numsteps,minDegree,maxDegree, takeunion=true)\n",
    "result = v.row\n",
    "\n",
    "# Vertices reached in 3 hops from specified users\n",
    "wordsrep = replace(words, \"word|\" => \" \")\n",
    "println(\"Vertices reached in \" * string(k) * \" hops from \" * wordsrep * \":\")\n",
    "for i = 1:length(result)\n",
    "    print(result[i][6:end] * \" \")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Jaccard index is a metric of similarity which can be calculated on a graph. In the context of words, this takes into account not only the number of times two words occur together, but also the overall degrees of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_TODO make this work, once Jaccard works too_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# % First remove low-degree nodes, those will throw off the results\n",
    "# w = Row(Adeg(realwords,:) > 2);\n",
    "# Atest = Awords(:,w);\n",
    "# Atest = Atest(w,:);\n",
    "\n",
    "# J = Jaccard(Atest);\n",
    "\n",
    "# J(['word|coffee' nl ],:)> 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will bind to a database. Often we put these lines in a script called \"DBsetup\" and just run that.\n",
    "\n",
    "Be sure to edit this to include a unique name for your tables, this will prevent multiply people from running on the same tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Aug 2019 13:47:17,297 WARN - ClientConfiguration.loadFromSearchPath(227) -  Found no client.conf in default paths. Using default client configuration values.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "D4M.DBserver(\"class-db02\", \"class-db02.cloud.llgrid.txe1.mit.edu:2181\", \"AccumuloUser\", \"aDvx@T_OwqfypNSnbcAMa14FV\", \"BigTableLike\", JavaCall.JavaObject{Symbol(\"edu.mit.ll.graphulo.MatlabGraphulo\")}(Ptr{Nothing} @0x0000000003dab6c0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize DB connectors\n",
    "dbinit()\n",
    "\n",
    "# Connect to Database\n",
    "\n",
    "DB = dbsetup(\"class-db02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting t2_Tedge in class-db02\n",
      "Deleting t2_TedgeDeg in class-db02\n",
      "Deleting t2_TedgeT in class-db02\n",
      "Deleting t2_TedgeTxt in class-db02\n",
      "Deleting t2_Tedge_BFS in class-db02\n",
      "Deleting t2_Tedge_BFST in class-db02\n",
      "Deleting t2_hashtag in class-db02\n",
      "Deleting t2_hashtag_user in class-db02\n",
      "Deleting t2_user_hashtag in class-db02\n",
      "Deleting t2_user_share_hashtag in class-db02\n",
      "Deleting t2_user_share_hashtag_bfs in class-db02\n",
      "Deleting t2_user_share_hashtag_bfsT in class-db02\n",
      "Deleting t2_user_share_hashtag_deg in class-db02\n",
      "Deleting t2_user_share_hashtag_jaccard in class-db02\n",
      "Deleting t2_wordword in class-db02\n",
      "Creating t2_Tedge in class-db02\n",
      "Creating t2_TedgeT in class-db02\n",
      "Creating t2_TedgeDeg in class-db02\n",
      "Creating t2_TedgeTxt in class-db02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "D4M.DBtable(D4M.DBserver(\"class-db02\", \"class-db02.cloud.llgrid.txe1.mit.edu:2181\", \"AccumuloUser\", \"aDvx@T_OwqfypNSnbcAMa14FV\", \"BigTableLike\", JavaCall.JavaObject{Symbol(\"edu.mit.ll.graphulo.MatlabGraphulo\")}(Ptr{Nothing} @0x0000000003dab6c0)), \"t2_TedgeTxt\", \"\", 0, 0, \"\", 500000.0, JavaCall.JavaObject{Symbol(\"edu.mit.ll.d4m.db.cloud.D4mDataSearch\")}(Ptr{Nothing} @0x000000000c3f5e58), JavaCall.JavaObject{Symbol(\"edu.mit.ll.d4m.db.cloud.D4mDbTableOperations\")}(Ptr{Nothing} @0x000000000c3f5df0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give a unique name prefix to prevent collisions in Accumulo\n",
    "myName = \"t2_\" # CHANGE THIS TO SOMETHING UNIQUE\n",
    "\n",
    "deleteprefix(DB, myName)\n",
    "\n",
    "# Bind to tables\n",
    "Tedge = DB[myName * \"Tedge\", myName * \"TedgeT\"]\n",
    "TedgeDeg = DB[myName * \"TedgeDeg\"]\n",
    "TedgeTxt = DB[myName * \"TedgeTxt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the Accumulo monitor, these tables are now present!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will ingest our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i = 1:10\n",
    "#     A = ReadCSV(\"graphclassdata/A\" * string(i) * \".csv\")\n",
    "#     put(Tedge,A, clear = (i==1 ? true : false))\n",
    "#     put(TedgeDeg,transpose(sum(A,1)), clear = (i==1 ? true : false))\n",
    "#     println(i)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = ReadCSV(\"graphclassdata/A1.csv\");\n",
    "# println(\"1\")\n",
    "# A += ReadCSV(\"graphclassdata/A2.csv\")\n",
    "# println(\"2\")\n",
    "# A += ReadCSV(\"graphclassdata/A3.csv\")\n",
    "# println(\"3\")\n",
    "# A += ReadCSV(\"graphclassdata/A4.csv\")\n",
    "# println(\"4\")\n",
    "# A += ReadCSV(\"graphclassdata/A5.csv\")\n",
    "# println(\"5\")\n",
    "# A += ReadCSV(\"graphclassdata/A6.csv\")\n",
    "# println(\"6\")\n",
    "# A += ReadCSV(\"graphclassdata/A7.csv\")\n",
    "# println(\"7\")\n",
    "# A += ReadCSV(\"graphclassdata/A8.csv\")\n",
    "# println(\"8\")\n",
    "# A += ReadCSV(\"graphclassdata/A9.csv\")\n",
    "# println(\"9\")\n",
    "# A += ReadCSV(\"graphclassdata/A10.csv\")\n",
    "# println(\"10\")\n",
    "\n",
    "# A = Assoc(A.row, A.col, A.val, convert.(Int64, A.A))\n",
    "# # put(Tedge,A, clear=true)\n",
    "# # put(TedgeDeg,transposeusing JLD(sum(A,1)), clear=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating t2_Tedge in class-db02\n",
      "Creating t2_TedgeT in class-db02\n",
      "Creating t2_TedgeDeg in class-db02\n"
     ]
    }
   ],
   "source": [
    "using SparseArrays\n",
    "A = ReadJLD(\"graphclassdata/A.jld\");\n",
    "put(Tedge,A, clear=true)\n",
    "put(TedgeDeg,transpose(sum(A,1)), clear=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creating Adjacency Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store our data in an incidence matrix form using the standard D4M Schema. In this way you have the flexibility to create adjacency matrices of individual graphs as you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/d4mschema.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Graphulo's table multiply to create our adjacency matrices. For our twitter data, we can create several that may be interesting. First let's get the column keys of the columns we may want to filter on, and get an idea of how many columns there are in each using the degree table. This information is important when deciding how to form your adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25147 words that start with a letter.\n",
      "There are 1118 hashtags.\n",
      "There are 5474 words that start with @.\n",
      "There are 8510 usernames.\n",
      "There are 7705 locations.\n"
     ]
    }
   ],
   "source": [
    "# All words that start with a letter:\n",
    "realwords = \"word_lower|a,:,word_lower|z\" * Char(127) * \",\";\n",
    "println(\"There are \" * string(nnz(TedgeDeg[realwords,:])) * \" words that start with a letter.\")\n",
    "# should be 25147\n",
    "\n",
    "# All hashtags:\n",
    "hashtags = StartsWith(\"word|#\");\n",
    "println(\"There are \" * string(nnz(TedgeDeg[hashtags,:])) * \" hashtags.\")\n",
    "# should be 1118\n",
    "\n",
    "# Tweets @ someone:\n",
    "directedtweet = StartsWith(\"word|@\");\n",
    "println(\"There are \" * string(nnz(TedgeDeg[directedtweet,:])) * \" words that start with @.\")\n",
    "# should be 5474\n",
    "\n",
    "# Usenames:\n",
    "users = StartsWith(\"user|\");\n",
    "println(\"There are \" * string(nnz(TedgeDeg[users,:])) * \" usernames.\")\n",
    "# should be 8510\n",
    "\n",
    "# Locations:\n",
    "locs = StartsWith(\"latlon|\");\n",
    "println(\"There are \" * string(nnz(TedgeDeg[locs,:])) * \" locations.\")\n",
    "# should be 7705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a few graphs. A Graphulo Table Multiply gives us A\\*B, but takes in A' and B. Letting E be our incidence matrix, we can get an adjacency matrix by doing E'\\*E, so A = E' and B = E. Graphulo requires A' to multiply, and A' = (E')' = E."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's make a word-word graph. On the full dataset, this takes about 3-5 minutes, but the result is nearly a 1Mx1M graph with about 40M edges! Since this is a small subset, it only takes a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Aug 2019 13:48:10,698 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 525654 entries processed\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "ATtable = Tedge\n",
    "Btable = Tedge\n",
    "Cname = myName * \"wordword\"\n",
    "\n",
    "# Multiply Tables\n",
    "wordword = tablemult(ATtable, Btable, Cname, colfilterAT = realwords, colfilterB = realwords, clear=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [word_lower|abrigado , word_lower|abrigado]  =  1\n",
      "  [word_lower|hijo     , word_lower|abrigado]  =  1\n",
      "  [word_lower|m?s      , word_lower|abrigado]  =  1\n",
      "  [word_lower|voy      , word_lower|abrigado]  =  1\n",
      "  [word_lower|abrir    , word_lower|abrir   ]  =  2\n",
      "  [word_lower|acabo    , word_lower|abrir   ]  =  1\n",
      "  [word_lower|acho     , word_lower|abrir   ]  =  1\n",
      "  [word_lower|adivinha?, word_lower|abrir   ]  =  1\n",
      "  [word_lower|atrasada , word_lower|abrir   ]  =  2\n",
      "  [word_lower|boca     , word_lower|abrir   ]  =  1\n",
      "  [word_lower|cortando , word_lower|abrir   ]  =  1\n",
      "  [word_lower|estou    , word_lower|abrir   ]  =  1\n",
      "  [word_lower|eu       , word_lower|abrir   ]  =  2\n",
      "  [word_lower|gengiva  , word_lower|abrir   ]  =  1\n",
      "  [word_lower|kkkk     , word_lower|abrir   ]  =  1\n",
      "  [word_lower|loja..   , word_lower|abrir   ]  =  1\n",
      "  [word_lower|minha    , word_lower|abrir   ]  =  1\n",
      "  [word_lower|muito    , word_lower|abrir   ]  =  1\n",
      "  [word_lower|pra      , word_lower|abrir   ]  =  2\n",
      "  [word_lower|se       , word_lower|abrir   ]  =  1\n",
      "  [word_lower|sempre   , word_lower|abrir   ]  =  1\n",
      "  [word_lower|tudo     , word_lower|abrir   ]  =  1\n"
     ]
    }
   ],
   "source": [
    "# change to iterators\n",
    "print(wordword[:, StartsWith(\"word_lower|abri\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we want to see what hashtags are used together. Let's make a hashtag-hashtag graph. On the full dataset is much faster than the previous one and takes about a minute. On this subset it takes only a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Aug 2019 13:48:17,302 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 3921 entries processed\n",
      "  2.308884 seconds (121.16 k allocations: 6.033 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "ATtable = Tedge\n",
    "Btable = Tedge\n",
    "Cname = myName * \"hashtag\"\n",
    "\n",
    "rowFilter = \"\"\n",
    "colFilterAT = hashtags\n",
    "colFilterB = hashtags\n",
    "\n",
    "# Multiply Tables\n",
    "@time hashtag = tablemult(ATtable, Btable, Cname, colfilterAT = hashtags, colfilterB = hashtags, clear=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [word|#1            , word|#earthquake]  =  1\n",
      "  [word|#16           , word|#earthquake]  =  1\n",
      "  [word|#Breaking?    , word|#earthquake]  =  2\n",
      "  [word|#PastHour     , word|#earthquake]  =  2\n",
      "  [word|#earthquake   , word|#earthquake]  =  3\n",
      "  [word|#prayfromjapan, word|#earthquake]  =  2\n",
      "  [word|#quake        , word|#earthquake]  =  1\n",
      "  [word|#tsunami      , word|#earthquake]  =  2\n",
      "  [word|#Aunty        , word|#eat       ]  =  1\n",
      "  [word|#Thanks       , word|#eat       ]  =  1\n",
      "  [word|#cake         , word|#eat       ]  =  1\n",
      "  [word|#cheesecake.  , word|#eat       ]  =  1\n",
      "  [word|#delicious    , word|#eat       ]  =  1\n",
      "  [word|#eat          , word|#eat       ]  =  1\n",
      "  [word|#iloveit      , word|#eat       ]  =  1\n",
      "  [word|#sweet        , word|#eat       ]  =  1\n",
      "  [word|#yummi        , word|#eat       ]  =  1\n"
     ]
    }
   ],
   "source": [
    "print(hashtag[:,StartsWith(\"word|#ea\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a directed graph that shows which users use which hashtags.\n",
    "\n",
    "If you are creating an adjacency matrix for a directed graph, you may want to create a transpose result graph as well, so you can query quickly for both in and out vetices (Accumulo is indexed by row key, so it is fastest to query rows). All previous graphs were symmetric so you don't need a transpose adjacency matrix.\n",
    "\n",
    "I have also found that you want to use the filter with the larger number of values as your colFilterB- it will allow the iterator to process more entries at a time when it scanning from your A and B tables.\n",
    "\n",
    "For example, the first time I created the user-hashtag graph on the full dataset I set colFilterAT as the \"user|\" prefix and colFilterB as the \"word|#\" prefix. I eventually killed the process because it was taking a very long time (see below). When I swapped them, it took about a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/graphulo-colfilters.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you would multiply two tables and produce a transpose result matrix as well. Since you are calling a Java function, it is very picky about what inputs you use. I am just using the default values for the added parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Aug 2019 13:48:19,635 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 1553 entries processed\n",
      "  2.202923 seconds (13.98 k allocations: 794.123 KiB)\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "ATtable = Tedge\n",
    "Btable = Tedge\n",
    "Cname = myName * \"hashtag_user\"\n",
    "CTname = myName * \"user_hashtag\"\n",
    "\n",
    "# Multiply Tables\n",
    "@time hashtaguser = tablemult(ATtable, Btable, Cname, CTname, colfilterAT = hashtags, colfilterB = users);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [word|#OmSpikTanya   , user|AnesEsa       ]  =  2\n",
      "  [word|#kepo          , user|Annisa1309_   ]  =  1\n",
      "  [word|#hoytocasiesta!, user|AntonellaVolpi]  =  1\n"
     ]
    }
   ],
   "source": [
    "print(hashtaguser[:,StartsWith(\"user|An\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want a graph that describes the users that use the same hashtags? That will take two steps. First create an adjacency matrix of users-hashtags by multiplying (we already created this in the previous example). Then, using the graph you have just made, multiplying again will create the graph you are looking for.\n",
    "\n",
    "Since we are multiplying the full table, we don't need to provide any filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Aug 2019 13:48:19,996 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 7142 entries processed\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "# Multiply in terms of A*B = C, so if we want to do A'*B, then AT is just A\n",
    "ATtable = hashtaguser\n",
    "Btable = hashtaguser\n",
    "Cname = myName * \"user_share_hashtag\"\n",
    "\n",
    "# Multiply Tables\n",
    "usersharehashtag = tablemult(ATtable, Btable, Cname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [user|AceATamayo     , user|AceATamayo]  =  1\n",
      "  [user|Ace_Cauyan     , user|AceATamayo]  =  1\n",
      "  [user|Camimimimille  , user|AceATamayo]  =  1\n",
      "  [user|FRlENSHIP      , user|AceATamayo]  =  1\n",
      "  [user|FaryllJoiz     , user|AceATamayo]  =  1\n",
      "  [user|HeyJirko27     , user|AceATamayo]  =  1\n",
      "  [user|HolaAngelicAnne, user|AceATamayo]  =  2\n",
      "  [user|KhimUlit       , user|AceATamayo]  =  2\n",
      "  [user|aiiiidy        , user|AceATamayo]  =  1\n",
      "  [user|buscasFaye13   , user|AceATamayo]  =  1\n",
      "  [user|camillevllnva  , user|AceATamayo]  =  2\n",
      "  [user|conhalili      , user|AceATamayo]  =  1\n",
      "  [user|elsiejeline    , user|AceATamayo]  =  1\n",
      "  [user|howtogain      , user|AceATamayo]  =  1\n",
      "  [user|iamrenzijohn   , user|AceATamayo]  =  1\n",
      "  [user|im_shufflin    , user|AceATamayo]  =  1\n",
      "  [user|itsjhengXI     , user|AceATamayo]  =  1\n",
      "  [user|izecanFLY      , user|AceATamayo]  =  2\n",
      "  [user|juliannejomocan, user|AceATamayo]  =  1\n",
      "  [user|katrinatella   , user|AceATamayo]  =  1\n",
      "  [user|librebetina    , user|AceATamayo]  =  1\n",
      "  [user|ohyesitsKC     , user|AceATamayo]  =  1\n",
      "  [user|sarcaXIM       , user|AceATamayo]  =  2\n",
      "  [user|sinikoaysitikss, user|AceATamayo]  =  1\n",
      "  [user|sndrglr        , user|AceATamayo]  =  1\n",
      "  [user|styles_trisha  , user|AceATamayo]  =  1\n",
      "  [user|AceATamayo     , user|Ace_Cauyan]  =  1\n",
      "  [user|Ace_Cauyan     , user|Ace_Cauyan]  =  2\n",
      "  [user|Camimimimille  , user|Ace_Cauyan]  =  1\n",
      "  [user|FRlENSHIP      , user|Ace_Cauyan]  =  1\n",
      "  [user|FaryllJoiz     , user|Ace_Cauyan]  =  1\n",
      "  [user|HeyJirko27     , user|Ace_Cauyan]  =  1\n",
      "  [user|HolaAngelicAnne, user|Ace_Cauyan]  =  2\n",
      "  [user|IaMmaE4        , user|Ace_Cauyan]  =  1\n",
      "  [user|IamJsmn        , user|Ace_Cauyan]  =  1\n",
      "  [user|KhimUlit       , user|Ace_Cauyan]  =  2\n",
      "  [user|Melbinooo      , user|Ace_Cauyan]  =  1\n",
      "  [user|TweetyBirdddddd, user|Ace_Cauyan]  =  1\n",
      "  [user|aiiiidy        , user|Ace_Cauyan]  =  1\n",
      "  [user|ajayvictoria   , user|Ace_Cauyan]  =  1\n",
      "  [user|annnyyyyyyy    , user|Ace_Cauyan]  =  1\n",
      "  [user|buscasFaye13   , user|Ace_Cauyan]  =  1\n",
      "  [user|camillevllnva  , user|Ace_Cauyan]  =  2\n",
      "  [user|conhalili      , user|Ace_Cauyan]  =  1\n",
      "  [user|elsiejeline    , user|Ace_Cauyan]  =  1\n",
      "  [user|howtogain      , user|Ace_Cauyan]  =  1\n",
      "  [user|iRishLangdoN   , user|Ace_Cauyan]  =  1\n",
      "  [user|iamrenzijohn   , user|Ace_Cauyan]  =  1\n",
      "  [user|im_shufflin    , user|Ace_Cauyan]  =  1\n",
      "  [user|itsJhaySays_   , user|Ace_Cauyan]  =  1\n",
      "  [user|itsjhengXI     , user|Ace_Cauyan]  =  1\n",
      "  [user|izecanFLY      , user|Ace_Cauyan]  =  2\n",
      "  [user|juliannejomocan, user|Ace_Cauyan]  =  1\n",
      "  [user|katrinatella   , user|Ace_Cauyan]  =  1\n",
      "  [user|librebetina    , user|Ace_Cauyan]  =  1\n",
      "  [user|ohyesitsKC     , user|Ace_Cauyan]  =  1\n",
      "  [user|sarcaXIM       , user|Ace_Cauyan]  =  2\n",
      "  [user|sinikoaysitikss, user|Ace_Cauyan]  =  1\n",
      "  [user|sndrglr        , user|Ace_Cauyan]  =  1\n",
      "  [user|styles_trisha  , user|Ace_Cauyan]  =  1\n",
      "  [user|xxdananana     , user|Ace_Cauyan]  =  1\n"
     ]
    }
   ],
   "source": [
    "# usersharehashtaglocal = usersharehashtag[:, :]\n",
    "# usersharehashtaglocalnodiag = removediag(usersharehashtaglocal)\n",
    "# print(usersharehashtaglocalnodiag[:, StartsWith(\"user|Ac\")])\n",
    "print(usersharehashtag[:, StartsWith(\"user|Ac\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other graphs can you create that might be interesting? Try making some now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Graph Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree-Filtered Breadth First Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you are interested in seeing people that talk about similar things. You may have a handful of target individuals (maybe selected because they talk a lot about a topic), and want to get their 2-hop neighbors. You could do this by running breadth first search (BFS) on those individuals on the graph we generated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are doing degree filtering, we'll first generate a degree table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Degree Table to Degree Filtering\n",
    "usersharehashtagdegname=myName * \"user_share_hashtag_deg\"\n",
    "\n",
    "usersharehashtagdeg = makedegreetable(usersharehashtag, usersharehashtagdegname, countColumns=true, colq=\"deg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lots of degree 1 -- we didn't filter out the diagonal on Graphulo. Degree filtering can help us with this!\n",
    "# Also, for convenience, we can also view all the entries that are greater than 1, as follows:\n",
    "# u = usersharehashtagdeg[:, :]\n",
    "# uparse = str2num(u)\n",
    "# printFull(uparse>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run BFS. I picked two users mostly at random as our starting vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating t2_user_share_hashtag_bfs in class-db02\n",
      "Deleting t2_user_share_hashtag_bfs in class-db02\n",
      "13 Aug 2019 13:51:02,338 DEBUG - Graphulo.OneTable(987) -  user|viiocious :%00; [3] -> 33 entries processed\n",
      "13 Aug 2019 13:51:02,461 DEBUG - Graphulo.OneTable(987) -  user|viiocious :%00; [24] -> 315 entries processed\n",
      "\n",
      "Vertices reached in 2 hops from  smilevvsmilevv, OrenTsur, viiocious, (49 total):\n",
      "user|3lowshal7aeyaii, user|AleshkaLamanov, user|Alesyafedotova, user|Canniagoyessie, user|DudnikD, user|Ghassan366, user|HajiArefi, user|Indraputr4, user|IndryOktafiany, user|Mmmjj55, user|NadiaSaftiyan, user|Nakkarin_P, user|NatashaTyugaeva, user|NottinghamTIC, user|OrenTsur, user|PRINCESS_mony9, user|PalamarVeronika, user|SAIF_HA, user|SalmaAlQibti, user|StasAntonov, user|SueChua, user|SuzanneTee0217, user|Vanya_Cherevko, user|WulaaanWP, user|ZELO96_BTHB, user|_fosa, user|aboabdolla8, user|aisyyahs, user|akhbarhurra, user|an_NoY_nr, user|andrebranca94, user|deadinyati, user|dianaraflata_, user|franchiaraihc, user|ghida0, user|iina_ona, user|mo7ammed____, user|mymemoly, user|noOpeXky, user|no_kawaii, user|rachmawatidewi, user|ravidarwin2, user|refa_mn_, user|rhisya3, user|smilevvsmilevv, user|t_8man, user|talhi20, user|tungnail_hee, user|viiocious, "
     ]
    }
   ],
   "source": [
    "users = \"user|smilevvsmilevv,user|OrenTsur,user|viiocious,\"\n",
    "\n",
    "## Run Breadth First Search on Adjancency Schema\n",
    "numsteps=2 # Number of steps\n",
    "v0=users\n",
    "Atable=DB[myName * \"user_share_hashtag\"]\n",
    "\n",
    "# Set results table\n",
    "Rname=myName * \"user_share_hashtag_bfs\"\n",
    "RnameTable = DB[Rname]\n",
    "delete(RnameTable)\n",
    "\n",
    "# Other BFS Params\n",
    "RnameT=Rname * \"T\"\n",
    "\n",
    "# Do BFS\n",
    "v = adjbfs(Atable, v0, numsteps, Rname, RnameT; minDegree=5, maxDegree=20, \n",
    "    ADegtable=usersharehashtagdegname, degColumn=\"deg\", degInColQ=false)\n",
    "bfsresult = RnameTable[:,:]\n",
    "\n",
    "# Cleanly printing the output\n",
    "v0rep = replace(v0, \"user|\" => \" \")\n",
    "println(\"\\nVertices reached in \" * string(numsteps) * \" hops from \" * v0rep * \" (\" * string(length(bfsresult.col)) * \" total):\")\n",
    "for i = 1:length(bfsresult.col)\n",
    "    print(bfsresult.col[i] * \", \")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your results change if you change the min and max degrees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jaccard index -- a similarity measure of two sets -- is another metric for saying how similar two users may be. In our example, we look at each user's set of hashtag sharers, and compute how similar the two sets are.\n",
    "\n",
    "A good explanation of the Jaccard Index, and how it works in the context of graph theory: https://medium.com/rapids-ai/similarity-in-graphs-jaccard-versus-the-overlap-coefficient-610e083b877d\n",
    "\n",
    "We can run Jaccard on the entire user-user graph in the database using Graphulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Aug 2019 13:51:11,577 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 121104 entries processed\n",
      "13 Aug 2019 13:51:11,577 DEBUG - Graphulo.Jaccard(3429) -  Jaccard #partial products 121104\n"
     ]
    }
   ],
   "source": [
    "# Set Params\n",
    "Aname=myName * \"user_share_hashtag\"\n",
    "Atable = DB[Aname]\n",
    "ADegtable=Aname * \"_deg\"\n",
    "Rfinal=Aname * \"_jaccard\"\n",
    "\n",
    "# Do Jaccard\n",
    "jaccard(Atable, ADegtable, Rfinal)\n",
    "\n",
    "# Set up Results Table\n",
    "TadjJaccard = DB[Rfinal];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9×3 Array{Union{AbstractString, Number},2}:\n",
       " \"\"                       \"user|RizaIcha12\"   \"user|NottinghamTIC\"\n",
       " \"user|12N_nadiya2\"      0.0327869           0.0                  \n",
       " \"user|Alesyafedotova\"   0.0                 0.125                \n",
       " \"user|DebbyAngrainiHD\"  0.0327869           0.0                  \n",
       " \"user|Indraputr4\"       0.0625              0.0                  \n",
       " \"user|IndryOktafiany\"   0.0625              0.0                  \n",
       " \"user|Mmmjj55\"          0.0                 0.2                  \n",
       " \"user|NadiaSaftiyan\"    0.0625              0.0                  \n",
       " \"user|NikeDcn4\"         0.0327869           0.0                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing selected Jaccard Coefficients\n",
    "using Random\n",
    "\n",
    "userDeg=DB[ADegtable]\n",
    "users = str2num(userDeg[:,:])\n",
    "u = getrow(strictbounded(users, 5, 20))\n",
    "J = str2float(TadjJaccard[u,:])\n",
    "cols = 3\n",
    "printFull( J[:, rand(1:size(J)[2], 2)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those users we found in our BFS example earlier, what do they talk about? We can run NMF to do some topic modeling.\n",
    "\n",
    "Since NMF runs on an Incidence matrix, we need to first filter our original Edge table down to the tweets written by our users of interest. The first step to doing this is running BFS on the incidence matrix. This will give us the rows of Tedge that correspond to those users. Then we can filter out just the words by using the Graphulo OneTable function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we run BFS (unfortunately calling BFS on the EdgeTable is a little messy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating t2_Tedge_BFS in class-db02\n",
      "13 Aug 2019 13:51:26,628 DEBUG - Graphulo.EdgeBFS(1445) -  fetchColumn :\t\n",
      "13 Aug 2019 13:51:26,630 DEBUG - EdgeBFSReducer.parseOptions(34) -  inColumnPrefixes: ,\n"
     ]
    }
   ],
   "source": [
    "## Run Breadth First Search on Incidence Schema\n",
    "k=1 # Number of step\n",
    "v0 = v\n",
    "Etablename=myName * \"Tedge\"\n",
    "Etable = DB[Etablename]\n",
    "\n",
    "# Set results table\n",
    "Rtablename=Etablename * \"_BFS\"\n",
    "TadjBFS = DB[Rtablename]\n",
    "\n",
    "# Other BFS Params\n",
    "RTtablename=Rtablename * \"T\"\n",
    "\n",
    "# Do BFS\n",
    "vGraphulo = edgebfs(Etable, v0, k, Rtablename, RTtablename;\n",
    "    EDegtable=Etablename * \"Deg\", degColumn=\"\", degInColQ=false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the original incidence matrix is filtered to just tweets with the users in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can filter out the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating t2_Tedge_filtered in class-db02\n",
      "Deleting t2_Tedge_filtered in class-db02\n",
      "Creating t2_Tedge_filtered in class-db02\n",
      "Creating t2_Tedge_filteredT in class-db02\n",
      "Deleting t2_Tedge_filteredT in class-db02\n",
      "Creating t2_Tedge_filteredT in class-db02\n"
     ]
    }
   ],
   "source": [
    "# TODO make this work in Graphulo, not locally\n",
    "\n",
    "# Making some handy bindings\n",
    "RtableT = DB[RTtablename]\n",
    "Rtable = DB[Rtablename]\n",
    "\n",
    "# Filter to just words\n",
    "RtableFilterlocal = RtableT[realwords,:]\n",
    "\n",
    "# Create a DB table, and upload\n",
    "RtableFilter = DB[myName * \"Tedge_filtered\"]\n",
    "put(RtableFilter, RtableFilterlocal, clear=true)\n",
    "RtableFilterT = DB[myName * \"Tedge_filteredT\"]\n",
    "put(RtableFilterT, RtableFilterlocal', clear=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can run NMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Aug 2019 13:52:12,235 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:12,510 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:13,524 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:14,067 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:15,255 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:16,207 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 351 entries processed\n",
      "13 Aug 2019 13:52:16,716 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:17,215 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 1 to t2_Tedge_filtered_NMF_Hprev: hdiff 0.0\n",
      "13 Aug 2019 13:52:17,438 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:18,756 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 71 entries processed\n",
      "13 Aug 2019 13:52:19,291 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:20,542 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:21,840 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 277 entries processed\n",
      "13 Aug 2019 13:52:22,315 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:22,848 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 53 entries processed\n",
      "13 Aug 2019 13:52:22,867 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 21 entries processed\n",
      "13 Aug 2019 13:52:22,868 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 2 to t2_word_NMF_H: hdiff 0.39622641509433965\n",
      "13 Aug 2019 13:52:23,669 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:24,601 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 73 entries processed\n",
      "13 Aug 2019 13:52:25,073 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:26,342 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:27,647 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 321 entries processed\n",
      "13 Aug 2019 13:52:28,131 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:28,662 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 62 entries processed\n",
      "13 Aug 2019 13:52:28,680 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 15 entries processed\n",
      "13 Aug 2019 13:52:28,680 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 3 to t2_Tedge_filtered_NMF_Hprev: hdiff 0.24193548387096775\n",
      "13 Aug 2019 13:52:29,394 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:32,316 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 72 entries processed\n",
      "13 Aug 2019 13:52:32,829 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:34,047 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:35,347 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 330 entries processed\n",
      "13 Aug 2019 13:52:35,845 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:36,377 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 57 entries processed\n",
      "13 Aug 2019 13:52:36,392 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:36,393 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 4 to t2_word_NMF_H: hdiff 0.15789473684210525\n",
      "13 Aug 2019 13:52:37,130 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:38,055 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 64 entries processed\n",
      "13 Aug 2019 13:52:38,515 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:39,763 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:40,712 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 324 entries processed\n",
      "13 Aug 2019 13:52:41,206 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:41,730 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 54 entries processed\n",
      "13 Aug 2019 13:52:41,744 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 5 entries processed\n",
      "13 Aug 2019 13:52:41,745 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 5 to t2_Tedge_filtered_NMF_Hprev: hdiff 0.09259259259259259\n",
      "13 Aug 2019 13:52:42,474 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:43,396 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 63 entries processed\n",
      "13 Aug 2019 13:52:43,880 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:45,138 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:46,061 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 316 entries processed\n",
      "13 Aug 2019 13:52:46,538 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:46,954 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 52 entries processed\n",
      "13 Aug 2019 13:52:46,970 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 2 entries processed\n",
      "13 Aug 2019 13:52:46,970 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 6 to t2_word_NMF_H: hdiff 0.038461538461538464\n",
      "13 Aug 2019 13:52:47,709 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:49,002 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 63 entries processed\n",
      "13 Aug 2019 13:52:49,458 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:50,711 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:52,008 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 302 entries processed\n",
      "13 Aug 2019 13:52:52,489 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:53,025 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 51 entries processed\n",
      "13 Aug 2019 13:52:53,040 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 1 entries processed\n",
      "13 Aug 2019 13:52:53,041 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 7 to t2_Tedge_filtered_NMF_Hprev: hdiff 0.0196078431372549\n",
      "13 Aug 2019 13:52:53,775 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:55,133 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 61 entries processed\n",
      "13 Aug 2019 13:52:55,577 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:52:56,777 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:52:58,071 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 310 entries processed\n",
      "13 Aug 2019 13:52:58,522 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:52:59,046 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 52 entries processed\n",
      "13 Aug 2019 13:52:59,060 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 3 entries processed\n",
      "13 Aug 2019 13:52:59,061 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 8 to t2_word_NMF_H: hdiff 0.057692307692307696\n",
      "13 Aug 2019 13:52:59,787 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:53:01,076 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 60 entries processed\n",
      "13 Aug 2019 13:53:01,526 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:53:02,763 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:53:04,051 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 310 entries processed\n",
      "13 Aug 2019 13:53:04,505 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:53:05,031 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 52 entries processed\n",
      "13 Aug 2019 13:53:05,045 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 9 to t2_Tedge_filtered_NMF_Hprev: hdiff 0.0\n",
      "13 Aug 2019 13:53:05,788 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:53:06,734 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 60 entries processed\n",
      "13 Aug 2019 13:53:07,183 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:53:08,463 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:53:09,322 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 310 entries processed\n",
      "13 Aug 2019 13:53:09,762 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:53:10,306 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 52 entries processed\n",
      "13 Aug 2019 13:53:10,320 DEBUG - Graphulo.NMF(3791) -  NMF Iteration 10 to t2_word_NMF_H: hdiff 0.0\n",
      "13 Aug 2019 13:53:11,019 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:53:12,321 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 60 entries processed\n",
      "13 Aug 2019 13:53:12,780 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 93 entries processed\n",
      "13 Aug 2019 13:53:14,016 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 9 entries processed\n",
      "13 Aug 2019 13:53:16,434 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 310 entries processed\n",
      "13 Aug 2019 13:53:16,904 DEBUG - Graphulo.TwoTable(770) -   :%00; [1] -> 468 entries processed\n",
      "13 Aug 2019 13:53:17,433 DEBUG - Graphulo.OneTable(987) -   :%00; [1] -> 52 entries processed\n",
      "13 Aug 2019 13:53:17,448 DEBUG - Graphulo.NMF(3801) -  ODD  Hfinal is t2_Tedge_filtered_NMF_Hprev\n",
      "13 Aug 2019 13:53:17,448 DEBUG - Graphulo.NMF(3802) -  ODD  Hprev is t2_word_NMF_H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NMF on Incidence/Edge Schema\n",
    "# Note: takes some time to run\n",
    "\n",
    "# Set results tables\n",
    "tname_W=myName * \"word_NMF_W\"\n",
    "TedgeNMF_W = DB[tname_W, tname_W * \"T\"]\n",
    "tname_H=myName * \"word_NMF_H\"\n",
    "TedgeNMF_H = DB[tname_H, tname_H * \"T\"]\n",
    "\n",
    "# Set Params\n",
    "Aorig=DB[myName * \"Tedge_filtered\"]\n",
    "ATorig=DB[myName * \"Tedge_filteredT\"]\n",
    "Wfinal= tname_W\n",
    "WTfinal= tname_W * \"T\"\n",
    "Hfinal= tname_H\n",
    "HTfinal= tname_H * \"T\"\n",
    "k=3 # Number of topics\n",
    "maxiter=20 # Maximum number of iterations\n",
    "\n",
    "# Do NMF\n",
    "nmf(Aorig, ATorig, k, Wfinal, WTfinal, Hfinal, HTfinal, maxiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the words of each topic. The information is stored in the W table of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157×4 Array{Union{AbstractString, Number},2}:\n",
       " \"\"                                    \"1\"          \"2\"          \"3\"       \n",
       " \"word_lower|ada\"                     0.0          0.0          3.25061    \n",
       " \"word_lower|ado\"                     0.0          0.0          0.288681   \n",
       " \"word_lower|aja\"                     0.0          0.582558     0.691934   \n",
       " \"word_lower|alasannya?\"              0.00131378   0.76175      0.0182819  \n",
       " \"word_lower|ang\"                     0.0          8.72533e-5   0.0        \n",
       " \"word_lower|anjing\"                  0.0250904    0.0          0.173126   \n",
       " \"word_lower|apa\"                    11.5075       0.0          0.0        \n",
       " \"word_lower|apaan?\"                  1.43874      0.0          0.0        \n",
       " \"word_lower|atau\"                    0.0          0.0          0.000453263\n",
       " \"word_lower|ayah\"                    0.0          0.206679     0.204627   \n",
       " \"word_lower|ba\"                      0.0          8.72533e-5   0.0        \n",
       " \"word_lower|baik\"                    0.0          4.5148       0.0        \n",
       " ⋮                                                                         \n",
       " \"word_lower|ttg\"                    11.5075       0.0          0.0        \n",
       " \"word_lower|tu\"                      0.0          0.0          0.288681   \n",
       " \"word_lower|tuisyen\"                 0.0          0.0          6.67112e-9 \n",
       " \"word_lower|tukar\\\"@auliaaafitri:\"   0.0          0.0          0.288681   \n",
       " \"word_lower|tunay\"                   0.0          8.72533e-5   0.0        \n",
       " \"word_lower|typo\"                    0.0          0.0          0.000453263\n",
       " \"word_lower|una\"                     0.0          3.67469e-10  0.0        \n",
       " \"word_lower|universal\"               0.0          8.76416e-7   0.0        \n",
       " \"word_lower|wkwk\"                    0.0          0.582558     0.691934   \n",
       " \"word_lower|xd\"                      0.0          0.0          6.67112e-9 \n",
       " \"word_lower|xl\"                      0.0          0.0          0.288681   \n",
       " \"word_lower|yg\"                      0.0         11.9636       0.0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WAssoc = str2float(TedgeNMF_W[:,:])\n",
    "printFull(WAssoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split the words into topics, and filter out the ones with low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "word_lower|apa\n",
      "word_lower|calon\n",
      "word_lower|eyang\n",
      "word_lower|kabar\n",
      "word_lower|pencalonan\n",
      "word_lower|pendapatmu\n",
      "word_lower|presiden\n",
      "word_lower|punya\n",
      "word_lower|sbg\n",
      "word_lower|subur\n",
      "word_lower|ttg\n",
      "\n",
      "Topic 2:\n",
      "word_lower|bekerja\n",
      "word_lower|dalam\n",
      "word_lower|dan\n",
      "word_lower|disiplin\n",
      "word_lower|kebohongan\n",
      "word_lower|pemimpin\n",
      "word_lower|pribadi\n",
      "word_lower|sama\n",
      "word_lower|seorang\n",
      "word_lower|tidak\n",
      "word_lower|yg\n",
      "\n",
      "Topic 3:\n",
      "word_lower|ada\n",
      "word_lower|gak\n",
      "word_lower|gak?\n",
      "word_lower|itu\n",
      "word_lower|kalau\n",
      "word_lower|kamu\n",
      "word_lower|kata\n",
      "word_lower|menurut\n",
      "word_lower|orang\n",
      "word_lower|pacar\n",
      "word_lower|rasa\n",
      "word_lower|salah\n"
     ]
    }
   ],
   "source": [
    "# Filter out only the highest value in each row, so that each word is associated with its topic\n",
    "\n",
    "M = Matrix(WAssoc.A)\n",
    "\n",
    "# TODO write a sortperm-based version\n",
    "\n",
    "width = size(M)[2]\n",
    "for i = 1:size(M)[1]\n",
    "    index = argmax(M[i,:])\n",
    "    for j = 1:width\n",
    "        if j != index\n",
    "            M[i, j] = 0\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "WAssoc2 = putAdj(WAssoc, D4M.sparse(M))\n",
    "\n",
    "# split into individual columns, with each column containing only one topic\n",
    "# also filtering out words with higher weights\n",
    "# for more / less results, change topN, or change the scalars\n",
    "topN = 11\n",
    "col1 = WAssoc2[:, 1].A\n",
    "cut1 = sort(col1, dims=1, rev=true)[topN] - 0.01\n",
    "# cut1 = sum(col1)/length(col1) * 2\n",
    "col2 = WAssoc2[:, 2].A\n",
    "# cut2 = sum(col2)/length(col2) * 2.5\n",
    "cut2 = sort(col2, dims=1, rev=true)[topN] - 0.01\n",
    "col3 = WAssoc2[:, 3].A\n",
    "# cut3 = sum(col3)length(col3) * 1\n",
    "cut3 = sort(col3, dims=1, rev=true)[topN] - 0.01\n",
    "\n",
    "println(\"Topic 1:\")\n",
    "println.((WAssoc2[:, 1] > cut1).row)\n",
    "println(\"\\nTopic 2:\")\n",
    "println.((WAssoc2[:, 2] > cut2).row)\n",
    "println(\"\\nTopic 3:\")\n",
    "println.((WAssoc2[:, 3] > cut3).row);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit hard to see if this makes any sense, since it's not in English. Using Google Translate or similar, we can see that at least the first two could make sense:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/topic1.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "<img src=\"images/topic2.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "<img src=\"images/topic3.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the tweets that are grouped into topics. First, we have to find the sets of Tweet IDs. We follow a similar process as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "4030149240881733\n",
      "422083534270881733\n",
      "589104590429781733\n",
      "6522994496781733\n",
      "677304766330881733\n",
      "739531693730881733\n",
      "804184452207781733\n",
      "844063821428781733\n",
      "\n",
      "Topic 2:\n",
      "121375375429781733\n",
      "253486513169781733\n",
      "35874956448781733\n",
      "359502688949781733\n",
      "378746561148781733\n",
      "4053126776781733\n",
      "624514187498781733\n",
      "\n",
      "Topic 3:\n",
      "42472996876781733\n",
      "441260120156781733\n",
      "635779414759781733\n",
      "652489168756781733\n",
      "673924555778781733\n",
      "825479379077781733\n",
      "846990361667781733\n",
      "848249482340881733\n",
      "8866479030881733\n"
     ]
    }
   ],
   "source": [
    "HAssoc = str2float(TedgeNMF_H[:,:])\n",
    "\n",
    "M = Matrix(HAssoc.A)\n",
    "\n",
    "l = size(M)[1]\n",
    "for i = 1:size(M)[2]\n",
    "    index = argmax(M[:,i])\n",
    "    for j = 1:l\n",
    "        if j != index\n",
    "            M[j, i] = 0\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "HAssoc2 = putAdj(HAssoc, D4M.sparse(M))\n",
    "\n",
    "row1 = HAssoc2[1, :].A\n",
    "# cut1 = sum(row1)/length(row1) * 0.00001\n",
    "cut1 = 10^-9\n",
    "row2 = HAssoc2[2, :].A\n",
    "cut2 = 10^-9\n",
    "# cut2 = sum(row2)/length(row2) * 0.1\n",
    "row3 = HAssoc2[3, :].A\n",
    "cut3 = 10^-8\n",
    "# cut3 = sum(row3)/length(row3)\n",
    "\n",
    "# left pad with zeros, so that we can use them to look up the actual tweets\n",
    "topic1cols = (HAssoc2[1, :] > cut1).col\n",
    "topic2cols = (HAssoc2[2, :] > cut2).col\n",
    "topic3cols = (HAssoc2[3, :] > cut3).col\n",
    "\n",
    "println(\"Topic 1:\")\n",
    "println.(topic1cols)\n",
    "println(\"\\nTopic 2:\")\n",
    "println.(topic2cols)\n",
    "println(\"\\nTopic 3:\")\n",
    "println.(topic3cols);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the full text of the tweets that were grouped into topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext = ReadCSV(\"graphclassdata/tweetsfulltext2.csv\", quotes=false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing associative arrays in databases is asynchronous.....here's things printed one cell at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9×2 Array{Union{AbstractString, Number},2}:\n",
       " \"\"                    …  \"Text\"                                                                                                                           \n",
       " \"4030149240881733\"       \"Apaan? NO!!!!\\\"@JawabJUJUR: Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\\\"\"        \n",
       " \"422083534270881733\"     \"sinting RT @JawabJUJUR: Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\"              \n",
       " \"589104590429781733\"     \"maymoop ituv\\\"@JawabJUJUR: Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\\\"\"         \n",
       " \"6522994496781733\"       \"Haha itu lucuRT@JawabJUJUR: Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\"          \n",
       " \"677304766330881733\"  …  \"Ga punya malu \\\"@JawabJUJUR: Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\\\"\"       \n",
       " \"739531693730881733\"     \"gak bnget @JawabJUJUR Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\"                \n",
       " \"804184452207781733\"     \"Kurang kerjaan pisan \\\"@JawabJUJUR: Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\\\"\"\n",
       " \"844063821428781733\"     \"what a hell!!!  \\\"@JawabJUJUR: Apa pendapatmu ttg kabar pencalonan eyang subur sbg calon presiden 2014? #JJ | @diahpuspa\\\"\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printFull(fulltext[topic1cols, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×3 Array{Union{AbstractString, Number},2}:\n",
       " \"\"                    …  \"Text\"                                                                                                                                   \n",
       " \"121375375429781733\"     \"Cuekin nnti jg baik sndri kok RT @JawabJUJUR: Kalo doi marah\"                                                                           \n",
       " \"253486513169781733\"     \"@fdrifda coy jangan ke saya coy hahaha\"                                                                                                 \n",
       " \"35874956448781733\"      \"RT @TweetRAMALAN: #Capricorn seorang pribadi yg tidak suka kebohongan\"                                                                  \n",
       " \"359502688949781733\"     \"Hhhaaa RT@TweetRAMALAN: #Capricorn seorang pribadi yg tidak suka kebohongan\"                                                            \n",
       " \"378746561148781733\"  …  \"- Natuklasan Mo na ba ang Tunay Nitong Ganda? http://t.co/UztKtdHaPG #Philippine #philippines #Mindanao #Manila #Luzon #leyte\\\"\"        \n",
       " \"4053126776781733\"       \"Natuklasan Mo na ba ang Tunay Nitong Ganda? http://t.co/UztKtdHaPG #Philippine #philippines #Mindanao #Manila #Luzon #leyte #Filipina\\\"\"\n",
       " \"624514187498781733\"     \"us \\\"@Tweetnesian: #TeenageQuestion pengen ke disneyland / universal studios ?\\\"\"                                                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printFull(fulltext[topic2cols, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×3 Array{Union{AbstractString, Number},2}:\n",
       " \"\"                    …  \"Text\"                                                                                                                                     \n",
       " \"42472996876781733\"      \"Gak\\\"@AhSpeakDoang: #OmSpikTanya lo dirumah punya anjing gak ?\\\"\"                                                                         \n",
       " \"441260120156781733\"     \"masa bodoooo :D RT @nankkatro04: @deadinyati masa?? RT\"                                                                                   \n",
       " \"635779414759781733\"     \"Ibu\\\"@AhSpeakDoang: #OmSpikTanya lo lebih deket sama ayah / ibu ?\\\"\"                                                                      \n",
       " \"652489168756781733\"     \"typo RT@rahna27: Mawah merah. @jawabJUJUR: [Cewek] Pilih mawar putih atau mawar merah? #JJ | @Dhea_Vanny\\\"\"                               \n",
       " \"673924555778781733\"  …  \"Ndk ado lai\"                                                                                                                              \n",
       " \"825479379077781733\"     \"wkwk aja \\\"@CAPALLL: heddeh RT @iina_ona: sama ja pngs sbnrnyav\\\"@CAPALLL: kd RT @iina_ona: kd pham kah ? (cont) http://t.co/wVlEIezJHt\\\"\"\n",
       " \"846990361667781733\"     \"Kalau rasa suka itu gak ada kata salah RT @JawabJUJUR: Suka sama pacar orang itu menurut kamu salah gak? #JJ | @luthfy_clouds\"            \n",
       " \"848249482340881733\"     \"bgt \\\"@AhSpeakDoang: #OmSpikTanya sering ngemil malem malem gak ??\\\"\"                                                                     \n",
       " \"8866479030881733\"       \"Gak\\\"@JawabJUJUR: Suka sama pacar orang itu menurut kamu salah gak? #JJ | @luthfy_clouds\\\"\"                                               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printFull(fulltext[topic3cols, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling tends to be fairly sensitive to the number of topics. Try varying k above and see how the resutls change. You can use Google Translate to see what the tweets are saying, to some degree. You can also try varying the maximum number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to start over, you can run this to delete your tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting t2_Tedge in class-db02\n",
      "Deleting t2_TedgeDeg in class-db02\n",
      "Deleting t2_TedgeT in class-db02\n",
      "Deleting t2_TedgeTxt in class-db02\n",
      "Deleting t2_Tedge_BFS in class-db02\n",
      "Deleting t2_Tedge_BFST in class-db02\n",
      "Deleting t2_Tedge_filtered in class-db02\n",
      "Deleting t2_Tedge_filteredT in class-db02\n",
      "Deleting t2_hashtag in class-db02\n",
      "Deleting t2_hashtag_user in class-db02\n",
      "Deleting t2_user_hashtag in class-db02\n",
      "Deleting t2_user_share_hashtag in class-db02\n",
      "Deleting t2_user_share_hashtag_bfs in class-db02\n",
      "Deleting t2_user_share_hashtag_bfsT in class-db02\n",
      "Deleting t2_user_share_hashtag_deg in class-db02\n",
      "Deleting t2_user_share_hashtag_jaccard in class-db02\n",
      "Deleting t2_word_NMF_H in class-db02\n",
      "Deleting t2_word_NMF_HT in class-db02\n",
      "Deleting t2_word_NMF_W in class-db02\n",
      "Deleting t2_word_NMF_WT in class-db02\n",
      "Deleting t2_wordword in class-db02\n"
     ]
    }
   ],
   "source": [
    "deleteprefix(DB, myName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
